<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>NEOMIND — PERSONAL CALM TRAINER</title>

  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;800;900&family=Sora:wght@300;400;600&display=swap" rel="stylesheet">

  <!-- Your main styles -->
  <link rel="stylesheet" href="../styles.css" />
</head>
<body class="project-page neomind-page">
  <!-- same header so MENU/WRITE + banner keep working if you want -->
  <header class="header">
    <a href="../index.html" class="link-group" aria-label="Go to home" data-cursor="Takes you home">
      <span class="menu-text">MENU</span>
    </a>

    <div id="hover-banner" class="hover-banner" aria-hidden="true">
      <span class="hover-text"></span>
    </div>

    <a href="https://www.behance.net/jyotirautela4" target="_blank" rel="noopener" class="link-group"
       aria-label="Go to write page" data-cursor="Takes you to my other projects">
      <span class="write-text">OTHER</span>
    </a>
  </header>

  <main class="project-main" aria-label="NEOMIND — PERSONAL CALM TRAINER">
    <!-- HERO IMAGE at the requested size/position -->
    <figure class="project-hero">
  <video
    class="hero-video"
    src="../public/2121 - Made with Clipchamp.mp4"
    autoplay
    muted
    loop
    playsinline
  ></video>
</figure>

    <!-- Meta row below the image (left label, right year) -->
    <div class="project-meta">
      <a class="meta-menu" href="../index.html">MENU</a>
      <span class="project-title">NEOMIND — PERSONAL CALM TRAINER</span>
      <span class="project-year">2024</span>
      <a class="meta-write" href="https://jrautela0398-oxemu.wordpress.com/" target="_blank" rel="noopener" >WRITE</a>
    </div>

    <hr class="project-divider">

    <!-- Your page content; scrolls naturally -->
    <section class="project-body">
      <section class="project-body">
  <p>
    Neomind is a small, low-cost biofeedback tool that helps you practice
    returning to your own calm baseline. A GSR sensor reads your skin signal,
    a simple number on the screen shows where your “calm band” is, and you use
    your breath to gently move the live value closer. Everything runs on an
    Arduino Uno, a basic sensor and a laptop, so it can sit on a desk at home,
    not only inside a lab.
  </p>
</section>

<section class="project-body">
  <h2>Problem</h2>
  <p>
    Many people know they should “take a deep breath”, but in stressful moments
    their body does not always follow. Most breathing or meditation apps use the
    same script for everyone, without knowing how your own calm state actually
    looks in your data. Neomind starts from a simple gap: we rarely see our
    “calm signature” in a concrete way, and we rarely practice coming back to it
    with feedback that is personal, not generic. This project treats calm as
    something you can observe, train toward, and slowly stabilise using a small
    home-built biofeedback loop.
  </p>
</section>

<div class="project-submeta">
  <span>Objective</span>
  <span>The Project</span>
</div>

<hr class="project-divider">

<div class="project-detail">
  <div class="col-left">
    <div>Biofeedback</div>
    <div>Daily practice</div>
  </div>

  <div class="col-right">
    <p>
      Neomind aims to turn a raw skin signal into a small, repeatable calm-training routine.
      First, it records your calm and anxious ranges to learn a personal “calm band”.
      In later sessions, the screen shows a target value from that band and your live reading
      side by side, and you use breath and posture to move closer.
      By logging these attempts over days, the project explores whether simple, low-cost
      biofeedback at home can stabilise breathing and increase time spent near one’s own calm state.
    </p>
  </div>
</div>

<section class="project-body">
  <h2>Core idea</h2>
  <p>
    Neomind works like a very small biofeedback trainer built around your own calm baseline,
    not a generic meditation script. The interaction is simple and repeats every day.
  </p>
  <ol>
    <li>
      <strong>Calibrate once.</strong> We record your GSR in two short phases:
      one when you are calm, and one when you recall or enter a mildly anxious state.
      This gives a personal calm band and a high-arousal band.
    </li>
    <li>
      <strong>Train daily.</strong> In later sessions, the screen shows a target
      value from your calm band and your live GSR reading. You adjust breath,
      posture and attention to gently move the live number toward that target.
    </li>
    <li>
      <strong>Observe change.</strong> Over days, we log how quickly you reach
      the calm band and how long you can stay near it, to see whether this small
      routine helps stabilise your breathing and awareness.
    </li>
  </ol>
</section>

<section class="nm-tile-row">
  <article class="nm-tile nm-tile--blue">
    <h3>Calibration</h3>
    <p>
      Short calm and mild-anxiety phases to learn your personal calm band
      and high-arousal band.
    </p>
    <video src="../public/neomind-calibration.mp4" controls playsinline></video>
  </article>

  <article class="nm-tile nm-tile--pink">
    <h3>Daily training</h3>
    <p>
      You match your breath and posture to a target from the calm band
      while watching the live value move.
    </p>
    <video src="../public/neomind-training.mp4" controls playsinline></video>
  </article>
</section>


<section class="project-body">
  <h2>Research framing</h2>

  <p>
    Neomind sits between a student prototype and a small pilot study.
    The questions are modest but concrete.
  </p>

  <p><strong>Research questions</strong></p>
  <ul>
    <li>
      What changes when people see their own calm band as a number,
      instead of following a generic breathing script?
    </li>
    <li>
      Over repeated sessions, do participants reach their calm band faster
      or stay near it for longer?
    </li>
    <li>
      How do people describe the experience of “chasing” a calm value:
      as calming, stressful, playful, or something else?
    </li>
  </ul>

  <p><strong>Aim</strong></p>
  <p>
    The aim is to test whether a very low-cost GSR setup can support
    everyday calm training in a simple, honest way. Rather than claiming
    clinical results, the project focuses on patterns: how signals, breath
    and self-report shift when people practice with Neomind over time.
  </p>
</section>

<div class="project-submeta">
  <span>THE PROCESS</span>
  <span>Pilot study</span>
</div>

<hr class="project-divider">

<div class="project-detail">
  <div class="col-left">
    <div>Participants</div>
    <div>Sessions</div>
    <div>Measures</div>
  </div>

  <div class="col-right">
    <p>
      I ran a small pilot with 10 people to see how Neomind behaves outside
      a lab. Each person used the tool in a quiet room, seated at a desk with
      a laptop and the GSR sensor on their fingers.
    </p>

    <p>
      For each person, we first did a short calibration: a calm phase and a
      mild-anxiety recall phase to learn their personal calm and high-arousal
      bands. In the same sitting, they then tried a training phase where the
      screen showed a target from their calm band and their live reading, and
      they used breathing and posture to move closer.
    </p>

    <p>
      During these sessions, I logged raw GSR values, the mapped calm / high
      bands, and simple features such as how long it took to reach the calm
      band and how long they could stay near it. After each trial, I also
      noted how people described the experience in their own words.
    </p>
  </div>
</div>

<section class="project-body">
  <h2>What we saw in the data</h2>
  <p>
    This is a small pilot, but some patterns were visible across people and sessions.
  </p>

  <ul>
    <li>
      Most participants could move their GSR value closer to the calm band
      within a few minutes when they actively focused on breathing.
    </li>
    <li>
      For several people, later sessions showed a shorter time to reach the
      calm band compared to their first attempt, suggesting a small learning
      effect.
    </li>
    <li>
      Some participants reported feeling calm even when the number was still
      outside the band, which raises questions about how people read their
      own signals versus how they feel.
    </li>
    <li>
      A few participants found “chasing the number” slightly stressful,
      which is important for designing future feedback that feels gentler
      and less competitive.
    </li>
  </ul>
</section>

<!-- Graph 1: first vs later sessions for one participant -->
<figure class="project-wide">
  <img src="../public/neomind-graph1.png"
       alt="Example participant: GSR traces for first and later sessions"
       loading="lazy">
  <figcaption>
    Example participant: GSR traces from an early session and a later session.
    Later, they reach and stay near their calm band more quickly.
  </figcaption>
</figure>

<!-- Graph 2: time in calm band across participants -->
<figure class="project-wide">
  <img src="../public/neomind-graph2.png"
       alt="Time spent in calm band across participants and sessions"
       loading="lazy">
  <figcaption>
    Time spent inside the calm band across participants and sessions.
    Bars hint at a small but visible shift for some people over repeated use.
  </figcaption>
</figure>
 <section class="project-body">
  <h2>How it felt to use Neomind</h2>
  <p>
    The prototype is simple, but people reacted to it in clear ways.
    These are a few patterns that came up across sessions.
  </p>

  <ul>
    <li>
      Several participants described the target number as a “small goal”
      that made them pay closer attention to their breath and shoulders.
    </li>
    <li>
      On some days, people felt calm even when the number was still outside
      the band, which led to short conversations about how stress sits in
      the body versus how we think we feel.
    </li>
    <li>
      A few people said that “chasing the number” felt a bit competitive,
      especially when they were already tired, which is important for
      softening the feedback in future versions.
    </li>
    <li>
      Many liked that the setup was small and informal: a laptop, a sensor,
      and a simple screen, not a hospital-like environment.
    </li>
  </ul>
</section>

<figure class="project-wide">
  <video
    src="../public/neomind-session.mp4"
    controls
    playsinline
  ></video>
  <figcaption>
    A typical Neomind session: laptop showing the target calm band and live
    value, with the GSR sensor on the participant’s fingers.
  </figcaption>
</figure>

<div class="project-submeta">
  <span>SYSTEM</span>
  <span>Hardware & software</span>
</div>

<hr class="project-divider">

<div class="project-detail">
  <div class="col-left">
    <div>Sensing</div>
    <div>Processing</div>
    <div>Feedback</div>
  </div>

  <div class="col-right">
    <p>
      Neomind uses a simple GSR sensor on the fingers, connected to an
      Arduino Uno. The board reads skin conductance as an analog signal at
      a fixed interval, applies light smoothing to reduce noise, and sends
      the values to a laptop over USB.
    </p>

    <p>
      During calibration, the system records short calm and anxious phases
      and stores the resulting ranges as a personal calm band and a
      high-arousal band. In daily sessions, a small desktop interface shows
      a target value from the calm band and the live GSR reading side by
      side, along with a simple indicator of whether the signal is moving
      toward or away from the calm range.
    </p>

    <p>
      The whole pipeline is deliberately minimal: off-the-shelf components,
      basic signal handling, and a clear mapping from numbers to a concrete
      task for the person—match the calm band with your breath and posture.
      This keeps the focus on practice and reflection rather than on a
      complex black-box algorithm.
    </p>
  </div>
</div>

<section class="project-body">
  <h2>From numbers to daily practice</h2>
  <p>
    Neomind does not try to diagnose or label emotions. It offers a small,
    everyday exercise: see your own calm band, and gently practice returning
    toward it with breath and posture.
  </p>
  <p>
    Over time, this kind of home biofeedback can support steadier breathing,
    more honest check-ins with the body, and small moments of recovery in a
    busy day. For me, it is also a way to test how ideas from affective
    computing and HCI can live in ordinary Indian homes, using parts that are
    affordable and easy to repair.
  </p>
</section>


<!-- END GRID (three columns under the carousel line) -->
<section class="end-grid" aria-label="Footer info">
  <div class="end-col end-left">
    <div class="end-kicker">CONTACT</div>
    <div class="end-block">
      <div class="end-strong">Phone . (+91) 7609948434</div>
      <div class="end-strong">Email . jrautela0399@gmail.com</div>
      <div class="end-strong">Pl . #1234</div>
    </div>
    <div class="end-small">©Jraw</div>
  </div>


  <div class="end-col end-right">
    <div class="end-kicker">FOLLOW</div>
    <nav class="end-list" aria-label="Social">
      <a href="https://github.com/jyotirautela0399-ux" target="_blank" class="end-strong">GITHUB</a>
      <a href="https://www.behance.net/jyotirautela4" target="_blank" class="end-strong">BEHANCE</a>
      <a href="https://www.linkedin.com/in/jyoti-rautela-b25a87118/" target="_blank" class="end-strong">LINKEDIN</a>
    </nav>
  </div>
</section>

  </main>

  <!-- Keep your cursor hint node (optional on project pages) -->
  <div id="cursor-hint" class="cursor-hint" aria-hidden="true"></div>

  <!-- You can reuse your existing script if you want banner/hint on this page too.
       If not needed, you can omit it. Keeping it consistent: -->
  <script>
  (() => {
    const banner  = document.getElementById('hover-banner');
    const textEl  = banner?.querySelector('.hover-text');
    const header  = document.querySelector('.header');
    const hint    = document.getElementById('cursor-hint');

    const titleOf = el =>
      (el.dataset?.title || el.getAttribute?.('aria-label') || el?.title ||
       el?.querySelector?.('img')?.alt || 'Project').trim();
    const writeOf = el => (el?.dataset?.cursor || titleOf(el)).trim();

    // cursor pill follow (unchanged)
    let hintTimer;
    function showHint(txt){ if(!hint||!txt) return; clearTimeout(hintTimer); hint.textContent=txt; hintTimer=setTimeout(()=>hint.classList.add('show'),80); }
    function hideHint(){ if(!hint) return; clearTimeout(hintTimer); hint.classList.remove('show'); }
    if (hint){
      addEventListener('pointermove', e => {
        const m=8, o=14, w=hint.offsetWidth||0, h=hint.offsetHeight||0;
        let x=Math.min(Math.max(m, e.clientX+o), innerWidth -w -m);
        let y=Math.min(Math.max(m, e.clientY+o), innerHeight-h -m);
        hint.style.setProperty('--tx', x+'px');
        hint.style.setProperty('--ty', y+'px');
      }, {passive:true});
    }

    // header hover hint only (no gallery on this page)
    header?.addEventListener('pointermove', e => {
      const el = e.target.closest?.('[data-cursor]');
      el ? showHint(writeOf(el)) : hideHint();
    }, {passive:true});
    header?.addEventListener('pointerleave', hideHint);

    // === Results box: counter as "04 of 04" ===
const rb = document.getElementById('resultBox');
if (rb){
  const slides    = rb.querySelectorAll('.rb-slide');
  const btnPrev   = rb.querySelector('.rb-prev');
  const btnNext   = rb.querySelector('.rb-next');
  const countWrap = rb.querySelector('.rb-count');

  const total = slides.length;
  let i = 0;

  const pad2 = n => String(n).padStart(2, '0');
  const renderCount = () => { if (countWrap) countWrap.textContent = `${pad2(i+1)} of ${pad2(total)}`; };
  renderCount();

  function show(n){
    slides[i].classList.remove('is-active');
    i = (n + total) % total;
    slides[i].classList.add('is-active');
    renderCount();
  }

  btnPrev?.addEventListener('click', () => show(i - 1));
  btnNext?.addEventListener('click', () => show(i + 1));

  // keyboard support when footer has focus
  rb.addEventListener('keydown', (e) => {
    if (e.key === 'ArrowRight') { e.preventDefault(); show(i + 1); }
    if (e.key === 'ArrowLeft')  { e.preventDefault(); show(i - 1); }
  });
}

// === Scroll carousel (true horizontal loop, inside the strip) ===
const ss = document.getElementById('scrollShow');
if (ss){
  const sticky = ss.querySelector('.ss-sticky');
  const track  = ss.querySelector('.ss-track');
  const prev   = ss.querySelector('.ss-prev');
  const next   = ss.querySelector('.ss-next');

  // 1) Build left/middle/right cycles so we can loop seamlessly
  const originals = Array.from(track.children);
  const perCycle  = originals.length;

  function buildLoop(){
    // right clones
    originals.forEach(n => track.appendChild(n.cloneNode(true)));
    // left clones (prepend in reverse order)
    for (let i = originals.length - 1; i >= 0; i--){
      track.insertBefore(originals[i].cloneNode(true), track.firstChild);
    }
  }
  buildLoop();

  // 2) Measurements
  let cycleW = 0;   // width of ONE logical cycle (original items)
  let baseX  = 0;   // start of the middle cycle
  let x      = 0;   // free-running coordinate
  let vx     = 0;   // velocity
  let rafId  = 0;

  function measure(){
    // We now have 3 cycles: left + middle + right
    const cycles = Math.round(track.children.length / perCycle); // expect 3
    cycleW = track.scrollWidth / cycles;     // exact because track has NO padding
    baseX  = cycleW;                         // middle cycle starts after one cycle
    if (!Number.isFinite(cycleW) || cycleW === 0) return;

    // set x to base (visually middle)
    x = baseX;
    render(); // draw once
  }

  // 3) Render using modulo so there is never a jump/bounce
  function normPos(px){
    // normalise (px - baseX) into [0, cycleW)
    let d = (px - baseX) % cycleW;
    if (d < 0) d += cycleW;
    return baseX + d;
  }
  function render(){
    if (!cycleW) return;
    const nx = normPos(x);
    track.style.transform = `translate3d(${-nx}px,0,0)`;
  }

  // 4) Smooth animator
  function tick(){
    x += vx;
    vx *= 0.90; // friction
    render();
    if (Math.abs(vx) > 0.08){
      rafId = requestAnimationFrame(tick);
    }else{
      rafId = 0;
    }
  }
  function kick(delta){
    vx += delta;
    if (!rafId) rafId = requestAnimationFrame(tick);
  }

  // 5) Wheel only on the carousel area → horizontal slide
  ss.addEventListener('wheel', (e) => {
    e.preventDefault();                  // stop vertical page scroll while on strip
    const speed = 0.7;                   // feel/tuning
    kick(e.deltaY * speed);              // finger bottom→top = positive deltaY
  }, { passive: false });

  // Buttons
  prev?.addEventListener('click', () => kick(-300));
  next?.addEventListener('click', () => kick(+300));

  // Measure after layout & on resize
  const doMeasure = () => requestAnimationFrame(measure);
  addEventListener('resize', doMeasure, { passive: true });
  doMeasure();
}




})();
(() => {
  const meta = document.querySelector('.project-page .project-meta');
  if (!meta) return;

  // a sentinel just above the meta row to detect when it reaches top:0
  const sentinel = document.createElement('div');
  sentinel.style.position = 'sticky';
  sentinel.style.top = '0';
  sentinel.style.height = '1px';
  sentinel.style.marginTop = '-1px';
  meta.before(sentinel);

  const io = new IntersectionObserver(
    ([e]) => {
      // when sentinel is NOT intersecting, meta is stuck to top
      if (!e.isIntersecting) meta.classList.add('is-stuck');
      else                   meta.classList.remove('is-stuck');
    },
    { threshold: 1.0 }
  );
  io.observe(sentinel);
})();


(() => {
  const meta = document.querySelector('.project-page .project-meta');
  if (!meta) return;

  // Document-top position of the meta bar
  const triggerTop = meta.getBoundingClientRect().top + window.scrollY;

  function onScroll(){
    if (window.scrollY >= triggerTop) {
      document.body.classList.add('meta-stuck');
    } else {
      document.body.classList.remove('meta-stuck');
    }
  }

  window.addEventListener('scroll', onScroll, { passive: true });
  window.addEventListener('resize', () => {
    // recalc in case fonts/layout change height
    const r = meta.getBoundingClientRect();
    // Keep trigger as "initial doc position of meta"
  }, { passive: true });

  onScroll(); // initialize
})();


(() => {
  const meta = document.querySelector('.project-page .project-meta');
  if (!meta) return;
  function tick(){ meta.classList.toggle('is-stuck', meta.getBoundingClientRect().top <= 0); }
  addEventListener('scroll', tick, {passive:true});
  addEventListener('resize', tick, {passive:true});
  tick();
})();


  
  </script>
  <script>
(() => {
  // turn off uniform grid gap so per-item margins matter
  const gallery = document.querySelector('.hero-gallery');
  if (!gallery) return;
  gallery.style.gap = '0px';

  const picks = ['.t1','.t5','.t6','.t7'];
  const rand = (min, max) => Math.floor(Math.random() * (max - min + 1)) + min;

  // random margins per tile (tweak ranges to taste)
  picks.forEach(sel => {
    const el = document.querySelector(sel);
    if (!el) return;
    const mt = rand(6, 28);
    const mr = rand(8, 32);
    const mb = rand(6, 26);
    const ml = rand(8, 30);
    el.style.margin = `${mt}px ${mr}px ${mb}px ${ml}px`;
  });
})();
</script>


</body>
</html>
